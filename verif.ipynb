{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e93cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "pgpass file created at C:\\Users\\JEAUL2\\AppData\\Roaming\\postgresql\\pgpass.conf\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36417e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980-01-02\n",
      "1981-01-02\n",
      "1982-01-02\n",
      "1983-01-02\n",
      "1984-01-02\n",
      "1985-01-02\n",
      "1986-01-02\n",
      "1987-01-02\n",
      "1988-01-02\n",
      "1989-01-02\n",
      "1990-01-02\n",
      "1991-01-02\n",
      "1992-01-02\n",
      "1993-01-02\n",
      "1994-01-02\n",
      "1995-01-02\n",
      "1996-01-02\n",
      "1997-01-02\n",
      "1998-01-02\n",
      "1999-01-02\n",
      "2000-01-02\n",
      "2001-01-02\n",
      "2002-01-02\n",
      "2003-01-02\n",
      "2004-01-02\n",
      "2005-01-02\n",
      "2006-01-02\n",
      "2007-01-02\n",
      "2008-01-02\n",
      "2009-01-02\n",
      "2010-01-02\n",
      "2011-01-02\n",
      "2012-01-02\n",
      "2013-01-02\n",
      "2014-01-02\n",
      "2015-01-02\n",
      "2016-01-02\n",
      "2017-01-02\n",
      "2018-01-02\n",
      "2019-01-02\n",
      "2020-01-02\n",
      "2021-01-02\n",
      "2022-01-02\n",
      "2023-01-02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import wrds\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "date = datetime(1980, 1, 2)\n",
    "os.makedirs(\"constituants_mkt\", exist_ok=True)\n",
    "\n",
    "all_stock = set()\n",
    "while date < datetime(2024, 1, 2):\n",
    "  date_str = date.strftime(\"%Y-%m-%d\")\n",
    "  print(date_str)\n",
    "  q = f\"\"\"\n",
    "      select a.permno, a.date, a.prc, a.shrout,\n",
    "        (abs(a.prc) * a.shrout * 1000) as market_cap,\n",
    "        b.ticker, b.comnam\n",
    "      from crsp.dsf a\n",
    "      join crsp.stocknames b\n",
    "        on a.permno = b.permno\n",
    "      and a.date between b.namedt and b.nameenddt\n",
    "      where a.date = (\n",
    "          select max(date) from crsp.dsf\n",
    "          where date <= '{date_str}'\n",
    "      )\n",
    "        and a.prc > 0\n",
    "        and a.shrout > 0\n",
    "      order by market_cap desc\n",
    "      limit 500;\n",
    "\n",
    "  \"\"\"\n",
    "  mrk_df = db.raw_sql(q)['permno']\n",
    "  mrk_csv = os.path.join('constituants_mkt', f\"{date.year}.csv\")\n",
    "  mrk_df.to_csv(mrk_csv, index=False)\n",
    "  \n",
    "  stocks =  mrk_df.tolist()\n",
    "  all_stock.update(stocks)\n",
    "\n",
    "  date += relativedelta(years=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99f68893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\n"
     ]
    }
   ],
   "source": [
    "print(len(all_stock))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee62b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e485ca4",
   "metadata": {},
   "source": [
    "### Le code plus haut extrait les 500 plus grosses market cap par années"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e944d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Facteurs FF sauvegardés -> ./wrds_exports\\returns_factor.csv\n",
      "[OK] RET sauvegardé -> ./wrds_exports\\returns_stocks.csv\n",
      "[OK] Stock price -> ./wrds_exports\\stocks_price.csv\n",
      "[OK] Market Cap sauvegardée -> ./wrds_exports\\market_cap.csv\n",
      "[OK] Secteurs CRSP (FF12) sauvegardés -> ./wrds_exports\\sector.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrds\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paramètres à adapter\n",
    "# ------------------------------------------------------------\n",
    "PERMNOS     = list(all_stock) # <-- ta liste de PERMNO (exemples)\n",
    "START_DATE  = \"1976-01-01\"\n",
    "END_DATE    = \"2025-01-01\"\n",
    "OUTPUT_DIR  = \"./wrds_exports\"\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) CRSP daily returns (RET) — ajustés splits & dividendes\n",
    "# ------------------------------------------------------------\n",
    "def get_crsp_returns(db, permnos, start, end):\n",
    "    \"\"\"\n",
    "    Récupère les rendements CRSP daily (RET) pour une liste de PERMNO.\n",
    "    RET inclut les distributions (dividendes) et les splits (ajustements CRSP).\n",
    "    Option : inclure les delisting returns (DLRET) sur le dernier jour.\n",
    "    \"\"\"\n",
    "    # Base: crsp.dsf\n",
    "    sql = f\"\"\"\n",
    "        select date, permno, ret\n",
    "        from crsp.dsf\n",
    "        where permno in ({\",\".join(str(int(x)) for x in permnos)})\n",
    "          and date between '{start}' and '{end}'\n",
    "        order by date, permno\n",
    "    \"\"\"\n",
    "    df = db.raw_sql(sql, date_cols=[\"date\"])\n",
    "\n",
    "    # Nettoyage RET -> float\n",
    "    df[\"ret\"] = pd.to_numeric(df[\"ret\"], errors=\"coerce\")  # coerce '.', 'B', 'C' éventuels en NaN\n",
    "\n",
    "    \n",
    "\n",
    "    return df  # colonnes : date, permno, ret\n",
    "\n",
    "\n",
    "def get_crsp_prices(db, permnos, start, end, adjust=\"split\"):\n",
    "    \"\"\"\n",
    "    Prix quotidiens CRSP pour une liste de PERMNO.\n",
    "    - Columns toujours renvoyées: date, permno, prc\n",
    "    - Si adjust=\"split\": ajoute adjprc = |prc| * cfacpr (ajusté des splits/stock dividends)\n",
    "    - include_delisting_price:\n",
    "        * ajoute une ligne à dlstdt si absente, avec prc = prev_prc * (1 + dlret)\n",
    "        * utile pour avoir une 'dernière cotation' cohérente le jour de radiation\n",
    "    Notes:\n",
    "      - prc est mis en valeur absolue (CRSP signe parfois le prix).\n",
    "      - adjprc n'ajuste PAS les dividendes cash (pour le total return, il faut cumuler les RET).\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1) Récup prix + facteurs d'ajustement (cfacpr)\n",
    "    sql = f\"\"\"\n",
    "        select date, permno, prc, cfacpr\n",
    "        from crsp.dsf\n",
    "        where permno in ({\",\".join(str(int(x)) for x in permnos)})\n",
    "          and date between '{start}' and '{end}'\n",
    "        order by date, permno\n",
    "    \"\"\"\n",
    "    px = db.raw_sql(sql, date_cols=[\"date\"])\n",
    "    # Nettoyage numérique\n",
    "    px[\"prc\"] = pd.to_numeric(px[\"prc\"], errors=\"coerce\").abs()\n",
    "    px[\"cfacpr\"] = pd.to_numeric(px[\"cfacpr\"], errors=\"coerce\")\n",
    "\n",
    "    \n",
    "    # 3) Ajustement split (adjprc)\n",
    "    if adjust == \"split\":\n",
    "        # cfacpr peut être NaN sur certaines dates très anciennes: mettre 1.0 par défaut\n",
    "        px[\"adjprc\"] = px[\"prc\"] * px[\"cfacpr\"].fillna(1.0)\n",
    "\n",
    "    # 4) Colonnes de sortie\n",
    "    cols = [\"date\", \"permno\", \"prc\"]\n",
    "    if adjust == \"split\":\n",
    "        cols.append(\"adjprc\")\n",
    "    return px[cols].sort_values([\"date\",\"permno\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) CRSP daily Market Cap = |PRC| * SHROUT * 1000\n",
    "# ------------------------------------------------------------\n",
    "def get_crsp_market_cap(db, permnos, start, end):\n",
    "    \"\"\"\n",
    "    Market cap quotidienne (ME) en dollars : |PRC| * SHROUT * 1000\n",
    "    PRC en $; SHROUT en milliers d’actions.\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "        select date, permno, prc, shrout\n",
    "        from crsp.dsf\n",
    "        where permno in ({\",\".join(str(int(x)) for x in permnos)})\n",
    "          and date between '{start}' and '{end}'\n",
    "        order by date, permno\n",
    "    \"\"\"\n",
    "    df = db.raw_sql(sql, date_cols=[\"date\"])\n",
    "    # to numeric + ME\n",
    "    df[\"prc\"] = pd.to_numeric(df[\"prc\"], errors=\"coerce\")\n",
    "    df[\"shrout\"] = pd.to_numeric(df[\"shrout\"], errors=\"coerce\")\n",
    "    df[\"me\"] = df[\"prc\"].abs() * df[\"shrout\"] * 1000.0  # dollars\n",
    "    return df  # colonnes : date, permno, prc, shrout, me\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Fama-French daily factors (WRDS library 'ff')\n",
    "# ------------------------------------------------------------\n",
    "def get_ff6_daily(db, start, end, to_decimal=False):\n",
    "    \"\"\"\n",
    "    Récupère FF5 + UMD (quotidien) sur WRDS et garantit les colonnes:\n",
    "    date, mktrf, smb, hml, rmw, cma, rf, umd.\n",
    "    - Si FF5 indisponible, on retombe sur FF3 et on met rmw/cma = NaN.\n",
    "    - Si UMD indisponible, on crée umd = NaN.\n",
    "    - On fait un merge outer pour garder l’union des dates (les manquants deviennent NaN).\n",
    "    - Option: convertir de % vers décimaux (to_decimal=True).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # 1) FF5 (fallback FF3 si besoin)\n",
    "    ff5 = None\n",
    "    for tbl in [\"ff.five_factors_daily\", \"ff.five_factors_2x3_daily\"]:\n",
    "        try:\n",
    "            ff5 = db.raw_sql(f\"\"\"\n",
    "                select date, mktrf, smb, hml, rmw, cma, rf\n",
    "                from {tbl}\n",
    "                where date between '{start}' and '{end}'\n",
    "                order by date\n",
    "            \"\"\", date_cols=[\"date\"])\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if ff5 is None:\n",
    "        # Fallback FF3 -> on crée rmw & cma = NaN\n",
    "        ff5 = db.raw_sql(f\"\"\"\n",
    "            select date, mktrf, smb, hml, rf\n",
    "            from ff.factors_daily\n",
    "            where date between '{start}' and '{end}'\n",
    "            order by date\n",
    "        \"\"\", date_cols=[\"date\"])\n",
    "        ff5[\"rmw\"] = pd.NA\n",
    "        ff5[\"cma\"] = pd.NA\n",
    "\n",
    "    # Coercion numérique\n",
    "    for col in [\"mktrf\", \"smb\", \"hml\", \"rmw\", \"cma\", \"rf\"]:\n",
    "        ff5[col] = pd.to_numeric(ff5[col], errors=\"coerce\")\n",
    "\n",
    "    # 2) UMD (momentum) — fallback NaN si table indispo\n",
    "    mom = None\n",
    "    for tbl in [\"ff.factors_momentum_daily\", \"ff.momentum_factors_daily\"]:\n",
    "        try:\n",
    "            mom = db.raw_sql(f\"\"\"\n",
    "                select date, umd\n",
    "                from {tbl}\n",
    "                where date between '{start}' and '{end}'\n",
    "                order by date\n",
    "            \"\"\", date_cols=[\"date\"])\n",
    "            break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if mom is None:\n",
    "        # Pas d'accès UMD -> créer un DataFrame aligné sur les dates de ff5\n",
    "        mom = ff5[[\"date\"]].copy()\n",
    "        mom[\"umd\"] = pd.NA\n",
    "    else:\n",
    "        mom[\"umd\"] = pd.to_numeric(mom[\"umd\"], errors=\"coerce\")\n",
    "\n",
    "    # 3) Merge outer = union des dates -> les séries manquantes seront NaN\n",
    "    ff = ff5.merge(mom, on=\"date\", how=\"outer\").sort_values(\"date\")\n",
    "    ff = ff.drop_duplicates(subset=[\"date\"]).reset_index(drop=True)\n",
    "\n",
    "    # 4) Option: passer de % à décimaux\n",
    "    if to_decimal:\n",
    "        cols = [\"mktrf\", \"smb\", \"hml\", \"rmw\", \"cma\", \"rf\", \"umd\"]\n",
    "        ff[cols] = ff[cols] / 100.0\n",
    "\n",
    "    return ff[[\"date\", \"mktrf\", \"smb\", \"hml\", \"rmw\", \"cma\", \"rf\", \"umd\"]]\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) get sector\n",
    "# ------------------------------------------------------------\n",
    "def get_crsp_sectors(db, permnos):\n",
    "    \"\"\"\n",
    "    Récupère les codes SIC depuis CRSP et mappe vers les 12 secteurs Fama-French.\n",
    "    Retourne un DataFrame avec permno, siccd, sector_name.\n",
    "    \"\"\"\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT DISTINCT sn.permno, sn.siccd\n",
    "        FROM crsp.stocknames sn\n",
    "        WHERE sn.permno IN ({\",\".join(str(int(x)) for x in permnos)})\n",
    "    \"\"\"\n",
    "    df = db.raw_sql(sql)\n",
    "\n",
    "    # Coerce numeric SIC\n",
    "    df[\"siccd\"] = pd.to_numeric(df[\"siccd\"], errors=\"coerce\")\n",
    "\n",
    "    # Mapping SIC → Fama-French 12 industries\n",
    "    FF12_MAP = {\n",
    "        \"Consumer NonDurables\": [(100, 999), (2000, 2399), (2700, 2749), (2770, 2799),\n",
    "                                 (3100, 3199), (3940, 3989)],\n",
    "        \"Consumer Durables\": [(2500, 2519), (2590, 2599), (3630, 3659), (3710, 3711),\n",
    "                              (3714, 3714), (3716, 3716), (3750, 3751), (3792, 3792),\n",
    "                              (3900, 3939), (3990, 3999)],\n",
    "        \"Manufacturing\": [(2520, 2589), (2600, 2699), (2750, 2769), (3000, 3099),\n",
    "                          (3200, 3569), (3580, 3629), (3700, 3709), (3712, 3713),\n",
    "                          (3715, 3715), (3717, 3749), (3752, 3791), (3793, 3799)],\n",
    "        \"Energy\": [(1200, 1399), (2900, 2999)],\n",
    "        \"Chemicals\": [(2800, 2829), (2840, 2899)],\n",
    "        \"Business Equipment\": [(3570, 3579), (3660, 3692), (3694, 3699),\n",
    "                               (3810, 3829), (7370, 7379)],\n",
    "        \"Telecom\": [(4800, 4899)],\n",
    "        \"Utilities\": [(4900, 4949)],\n",
    "        \"Shops\": [(5000, 5999)],\n",
    "        \"Health\": [(2830, 2839), (3693, 3693), (3840, 3859), (8000, 8099)],\n",
    "        \"Money\": [(6000, 6999)],\n",
    "        \"Other\": [(0, 9999)],  # catch-all par défaut\n",
    "    }\n",
    "\n",
    "    def map_sic_to_ff12(sic):\n",
    "        if pd.isna(sic):\n",
    "            return \"Other\"\n",
    "        sic = int(sic)\n",
    "        for sector, ranges in FF12_MAP.items():\n",
    "            for (low, high) in ranges:\n",
    "                if low <= sic <= high:\n",
    "                    return sector\n",
    "        return \"Other\"\n",
    "\n",
    "    df[\"sector_name\"] = df[\"siccd\"].apply(map_sic_to_ff12)\n",
    "\n",
    "    return df[[\"permno\", \"siccd\", \"sector_name\"]]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run & export CSV\n",
    "# ------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    # 3) Fama-French daily (pas de pivot: pas par permno)\n",
    "    ff_df = get_ff6_daily(db, START_DATE, END_DATE)  # to_decimal=True si tu veux en décimal\n",
    "    ff_csv = os.path.join(OUTPUT_DIR, \"returns_factor.csv\")\n",
    "    ff_df.to_csv(ff_csv, index=False)\n",
    "    print(f\"[OK] Facteurs FF sauvegardés -> {ff_csv}\")\n",
    "\n",
    "    # 1) RET (CRSP returns) -> pivot (date x permno)\n",
    "    ret_df = get_crsp_returns(db, PERMNOS, START_DATE, END_DATE)\n",
    "    ret_wide = ret_df.pivot_table(index=\"date\", columns=\"permno\", values=\"ret\", aggfunc=\"first\").reset_index()\n",
    "    ret_csv = os.path.join(OUTPUT_DIR, \"returns_stocks.csv\")\n",
    "    ret_wide.to_csv(ret_csv, index=False)\n",
    "    print(f\"[OK] RET sauvegardé -> {ret_csv}\")\n",
    "\n",
    "    # 2) PRIX (on prend adjprc si dispo, sinon prc) -> pivot\n",
    "    price_df = get_crsp_prices(db, PERMNOS, START_DATE, END_DATE, adjust=\"split\")\n",
    "    val_col = \"adjprc\" if \"adjprc\" in price_df.columns else \"prc\"\n",
    "    price_wide = price_df.pivot_table(index=\"date\", columns=\"permno\", values=val_col, aggfunc=\"first\").reset_index()\n",
    "    price_csv = os.path.join(OUTPUT_DIR, \"stocks_price.csv\")\n",
    "    price_wide.to_csv(price_csv, index=False)\n",
    "    print(f\"[OK] Stock price -> {price_csv}\")\n",
    "\n",
    "    # 2bis) Market Cap -> pivot\n",
    "    me_df = get_crsp_market_cap(db, PERMNOS, START_DATE, END_DATE)\n",
    "    me_wide = me_df.pivot_table(index=\"date\", columns=\"permno\", values=\"me\", aggfunc=\"first\").reset_index()\n",
    "    me_csv = os.path.join(OUTPUT_DIR, \"market_cap.csv\")\n",
    "    me_wide.to_csv(me_csv, index=False)\n",
    "    print(f\"[OK] Market Cap sauvegardée -> {me_csv}\")\n",
    "    \n",
    "    #secteur!\n",
    "    df_secteurs = get_crsp_sectors(db, PERMNOS)\n",
    "    sectors_csv = os.path.join(OUTPUT_DIR, \"sector.csv\")\n",
    "    df_secteurs.to_csv(sectors_csv, index=False)\n",
    "    print(f\"[OK] Secteurs CRSP (FF12) sauvegardés -> {sectors_csv}\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e66021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
